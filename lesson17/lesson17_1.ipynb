{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1225255e",
   "metadata": {},
   "source": [
    "### Tesseract-OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b03e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "\n",
    "model_path = \"models/frozen_east_text_detection.pb\"\n",
    "img = cv2.imread(\"images/car.jpg\")\n",
    "model = cv2.dnn.readNet(model_path)\n",
    "outputLayers = []\n",
    "outputLayers.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "outputLayers.append(\"feature_fusion/concat_3\")\n",
    "height, width, colorch = img.shape\n",
    "new_height = (height//32+1)*32\n",
    "new_width = (width//32+1)*32\n",
    "h_ratio = height/new_height\n",
    "w_ratio = width/new_width\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (new_width, new_height),\n",
    "                             (123.68, 116.78, 103.94), True)\n",
    "model.setInput(blob)\n",
    "(scores, geometry) = model.forward(outputLayers)\n",
    "rectangles = []\n",
    "confidence_score = []\n",
    "rows = geometry.shape[2]\n",
    "cols = geometry.shape[3]\n",
    "for y in range(0, rows):\n",
    "    for x in range(0, cols):\n",
    "        if scores[0][0][y][x] < 0.5:\n",
    "            continue\n",
    "        offset_x = x*4\n",
    "        offset_y = y*4\n",
    "        # gemetry map:top/right/bottom/left/rotation angle\n",
    "        bottom_x = int(offset_x + geometry[0][1][y][x])\n",
    "        bottom_y = int(offset_y + geometry[0][2][y][x])\n",
    "        top_x = int(offset_x - geometry[0][3][y][x])\n",
    "        top_y = int(offset_y - geometry[0][0][y][x])\n",
    "        rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "        confidence_score.append(float(scores[0][0][y][x]))\n",
    "final_boxes = non_max_suppression(np.array(rectangles),\n",
    "                                  probs=confidence_score,\n",
    "                                  overlapThresh=0.5)\n",
    "for (x1, y1, x2, y2) in final_boxes:\n",
    "    area = abs(x2-x1) * abs(y2-y1)\n",
    "    if area > 4000:\n",
    "        x1 = int(x1*w_ratio)\n",
    "        y1 = int(y1*h_ratio)\n",
    "        x2 = int(x2*w_ratio)\n",
    "        y2 = int(y2*h_ratio)\n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "cv2.imshow(\"EAST\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4bd61fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import copy # 引入 copy 模組用於深度複製\n",
    "\n",
    "model_path = \"models/frozen_east_text_detection.pb\"\n",
    "img = cv2.imread(\"images/car.jpg\")\n",
    "model = cv2.dnn.readNet(model_path)\n",
    "outputLayers = []\n",
    "outputLayers.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "outputLayers.append(\"feature_fusion/concat_3\")\n",
    "height, width, colorch = img.shape\n",
    "new_height = (height//32+1)*32\n",
    "new_width = (width//32+1)*32\n",
    "h_ratio = height/new_height\n",
    "w_ratio = width/new_width\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (new_width, new_height),\n",
    "                             (123.68, 116.78, 103.94), True)\n",
    "model.setInput(blob)\n",
    "(scores, geometry) = model.forward(outputLayers)\n",
    "rectangles = []\n",
    "confidence_score = []\n",
    "# 用於儲存旋轉矩形的四個頂點 (4, 2)\n",
    "rotated_boxes_coords = [] \n",
    "rows = geometry.shape[2]\n",
    "cols = geometry.shape[3]\n",
    "min_confidence = 0.5 # 設定最小信心分數\n",
    "\n",
    "for y in range(0, rows):\n",
    "    for x in range(0, cols):\n",
    "        if scores[0][0][y][x] < min_confidence:\n",
    "            continue\n",
    "            \n",
    "        d = geometry[0][:4, y, x] # [top, right, bottom, left]\n",
    "        angle = geometry[0][4][y][x] # 旋轉角度 theta\n",
    "\n",
    "        # 計算 sin 和 cos\n",
    "        cos_a = np.cos(angle)\n",
    "        sin_a = np.sin(angle)\n",
    "\n",
    "        # 輸出的特徵圖尺寸比輸入圖片小 4 倍，所以要乘以 4\n",
    "        offset_x = x*4.0\n",
    "        offset_y = y*4.0\n",
    "\n",
    "        # 計算邊界框的四個頂點 (基於 EAST 論文公式)\n",
    "        \n",
    "        # 頂點 1 (x1, y1)\n",
    "        x1 = int(offset_x - d[3] * cos_a - d[0] * sin_a)\n",
    "        y1 = int(offset_y - d[3] * sin_a + d[0] * cos_a)\n",
    "        \n",
    "        # 頂點 2 (x2, y2)\n",
    "        x2 = int(offset_x + d[1] * cos_a - d[0] * sin_a)\n",
    "        y2 = int(offset_y + d[1] * sin_a + d[0] * cos_a)\n",
    "        \n",
    "        # 頂點 3 (x3, y3)\n",
    "        x3 = int(offset_x + d[1] * cos_a + d[2] * sin_a)\n",
    "        y3 = int(offset_y + d[1] * sin_a - d[2] * cos_a)\n",
    "\n",
    "        # 頂點 4 (x4, y4)\n",
    "        x4 = int(offset_x - d[3] * cos_a + d[2] * sin_a)\n",
    "        y4 = int(offset_y - d[3] * sin_a - d[2] * cos_a)\n",
    "        \n",
    "        # --- NMS 需要的軸對齊矩形 ---\n",
    "        # 計算最小軸對齊外接矩形 (Min-Area Bounding Box)\n",
    "        min_x = np.min([x1, x2, x3, x4])\n",
    "        min_y = np.min([y1, y2, y3, y4])\n",
    "        max_x = np.max([x1, x2, x3, x4])\n",
    "        max_y = np.max([y1, y2, y3, y4])\n",
    "\n",
    "        rectangles.append((min_x, min_y, max_x, max_y))\n",
    "        confidence_score.append(float(scores[0][0][y][x]))\n",
    "        \n",
    "        # 儲存旋轉矩形的頂點資訊\n",
    "        rotated_boxes_coords.append(np.array([\n",
    "            [x1, y1], [x2, y2], [x3, y3], [x4, y4]\n",
    "        ]))\n",
    "\n",
    "# 1. 執行 NMS 濾除重疊的軸對齊矩形 (不再使用 return_indices)\n",
    "final_boxes_nms = non_max_suppression(np.array(rectangles),\n",
    "                                      probs=confidence_score,\n",
    "                                      overlapThresh=0.5)\n",
    "\n",
    "# 2. 找出通過 NMS 的矩形在原始列表中的索引\n",
    "# 注意：這是一個間接且可能效率較低的方法，但能解決 imutils 版本的限制。\n",
    "final_rotated_boxes = []\n",
    "# 將原始 rectangles 轉換為 NumPy 陣列以便比較\n",
    "rectangles_np = np.array(rectangles) \n",
    "# 由於 NMS 可能會對座標進行微調，我們不能直接進行全等比較。\n",
    "# 更穩健的方法是依賴於矩形數量和順序。但更安全的做法是使用一個標記陣列。\n",
    "\n",
    "# 假設 NMS 返回的順序和原始輸入順序一致 (這通常是 imutils 的行為)\n",
    "# 並且 NMS 輸出的是原始輸入的一個子集。\n",
    "\n",
    "# 使用一個標記陣列來追蹤哪些矩形被保留\n",
    "is_kept = np.zeros(len(rectangles_np), dtype=bool)\n",
    "\n",
    "# 為了防止浮點數誤差導致匹配失敗，我們將座標四捨五入到整數\n",
    "final_boxes_nms_int = np.round(final_boxes_nms).astype(int)\n",
    "rectangles_np_int = np.round(rectangles_np).astype(int)\n",
    "\n",
    "# 遍歷通過 NMS 的矩形\n",
    "for (fx1, fy1, fx2, fy2) in final_boxes_nms_int:\n",
    "    # 在原始矩形列表中尋找匹配項\n",
    "    # 找到所有座標都匹配的索引\n",
    "    matches = np.where((rectangles_np_int[:, 0] == fx1) & \n",
    "                       (rectangles_np_int[:, 1] == fy1) & \n",
    "                       (rectangles_np_int[:, 2] == fx2) & \n",
    "                       (rectangles_np_int[:, 3] == fy2))[0]\n",
    "    \n",
    "    if len(matches) > 0:\n",
    "        # 由於 NMS 可能會保留多個具有相同軸對齊外框，但不同旋轉資訊的框\n",
    "        # 我們只取第一個未被標記的匹配項的索引\n",
    "        for idx in matches:\n",
    "            if not is_kept[idx]:\n",
    "                final_rotated_boxes.append(rotated_boxes_coords[idx])\n",
    "                is_kept[idx] = True # 標記為已處理\n",
    "                break # 跳出內層迴圈，處理下一個 NMS 框\n",
    "\n",
    "# 3. 繪製結果\n",
    "for box_points_scaled in final_rotated_boxes:\n",
    "    # 原始頂點座標是基於 EAST 輸出尺寸的，需要映射回原圖尺寸\n",
    "    \n",
    "    # 複製一份頂點，避免修改原始列表中的 NumPy 陣列\n",
    "    box_points_scaled_copy = copy.deepcopy(box_points_scaled) \n",
    "    \n",
    "    # 將頂點座標映射回原圖尺寸\n",
    "    box_points_scaled_copy[:, 0] = box_points_scaled_copy[:, 0] * w_ratio\n",
    "    box_points_scaled_copy[:, 1] = box_points_scaled_copy[:, 1] * h_ratio\n",
    "    \n",
    "    # 確保頂點是整數\n",
    "    box_points = np.intp(box_points_scaled_copy)\n",
    "    \n",
    "    # 繪製旋轉矩形 (綠色)\n",
    "    cv2.polylines(img, [box_points], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "# 額外篩選：只繪製面積大於 4000 的框 (如果需要，可保留此邏輯)\n",
    "# 注意：在旋轉矩形的情況下，計算面積應使用 minAreaRect 或 Shoelace formula，\n",
    "# 但為了簡單，我們可以先假設通過 NMS 的都是感興趣的車牌。\n",
    "# 如果需要面積篩選，請在 NMS 之前或之後對旋轉矩形的實際面積進行計算。\n",
    "\n",
    "cv2.imshow(\"EAST Rotated License Plate Detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8409a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K4P1K\n",
      "更改\n",
      "\n",
      "輻\n",
      "\n",
      "片尺寸和製作縮\n",
      "清明 时 节 雨 纷纷 ， 路 上 行人 欲 断 魂 。\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread(\"images/number.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "text = pytesseract.image_to_string(img, lang=\"eng\")\n",
    "print(text.strip())\n",
    "\n",
    "img = cv2.imread(\"images/traditional.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "text = pytesseract.image_to_string(img, lang=\"chi_tra\")\n",
    "print(text.strip())\n",
    "\n",
    "img = cv2.imread(\"images/simple.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "text = pytesseract.image_to_string(img, lang=\"chi_sim\")\n",
    "print(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b575ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV\n",
      "Python 程式 設計\n",
      "DAT-4567\n"
     ]
    }
   ],
   "source": [
    "# 中英文參雜辨識\n",
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread(\"images/sample.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "text = pytesseract.image_to_string(img, lang=\"eng+chi_tra\")\n",
    "print(text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b108c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "測試 垂直 文 字\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread(\"images/traditional2.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "text = pytesseract.image_to_string(img, lang=\"chi_tra_vert\")\n",
    "print(text.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1147a8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 16 52 42 80 0\n",
      "4 49 52 70 80 0\n",
      "P 87 53 107 79 0\n",
      "1 125 52 140 80 0\n",
      "K 159 52 187 80 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread(\"images/number.jpg\")\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_w = img.shape[1]\n",
    "img_h = img.shape[0]\n",
    "boxes = pytesseract.image_to_boxes(img)\n",
    "print(boxes)\n",
    "for box in boxes.splitlines():\n",
    "    box = box.split(\" \")\n",
    "    character = box[0]\n",
    "    x = int(box[1])\n",
    "    y = int(box[2])\n",
    "    x2 = int(box[3])\n",
    "    y2 = int(box[4])\n",
    "    cv2.rectangle(img, (x, img_h - y),\n",
    "                  (x2, img_h - y2), (0, 255, 0), 1)\n",
    "    cv2.putText(img, character, (x, img_h - y2 - 10),\n",
    "                cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 1)\n",
    "cv2.imshow(\"Image\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e426f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "偵測和辨識出車牌文字!\n",
      "BBT:6566\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread(\"images/car.jpg\")\n",
    "model = cv2.dnn.readNet(\"models/frozen_east_text_detection.pb\")\n",
    "outputLayers = []\n",
    "outputLayers.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "outputLayers.append(\"feature_fusion/concat_3\")\n",
    "height, width, colorch = img.shape\n",
    "new_height = (height//32+1)*32\n",
    "new_width = (width//32+1)*32\n",
    "h_ratio = height/new_height\n",
    "w_ratio = width/new_width\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (new_width, new_height),\n",
    "                             (123.68, 116.78, 103.94), True)\n",
    "model.setInput(blob)\n",
    "(scores, geometry) = model.forward(outputLayers)\n",
    "rectangles = []\n",
    "confidence_score = []\n",
    "rows = geometry.shape[2]\n",
    "cols = geometry.shape[3]\n",
    "for y in range(0, rows):\n",
    "    for x in range(0, cols):\n",
    "        if scores[0][0][y][x] < 0.5:\n",
    "            continue\n",
    "        offset_x = x*4\n",
    "        offset_y = y*4\n",
    "        bottom_x = int(offset_x + geometry[0][1][y][x])\n",
    "        bottom_y = int(offset_y + geometry[0][2][y][x])\n",
    "        top_x = int(offset_x - geometry[0][3][y][x])\n",
    "        top_y = int(offset_y - geometry[0][0][y][x])\n",
    "        rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "        confidence_score.append(float(scores[0][0][y][x]))\n",
    "\n",
    "final_boxes = non_max_suppression(np.array(rectangles),\n",
    "                                  probs=confidence_score,\n",
    "                                  overlapThresh=0.5)\n",
    "for (x1, y1, x2, y2) in final_boxes:\n",
    "    w = abs(x2-x1)\n",
    "    h = abs(y2-y1)\n",
    "    area = w * h\n",
    "    if area > 4000:\n",
    "        x1 = int(x1*w_ratio)\n",
    "        y1 = int(y1*h_ratio)\n",
    "        x2 = int(x2*w_ratio)\n",
    "        y2 = int(y2*h_ratio)\n",
    "        print(\"偵測和辨識出車牌文字!\")\n",
    "        result = img[y1-10:y1+h+13, x1-10:x1+w+1]\n",
    "        cv2.imshow(\"Plate\", result)\n",
    "        text = pytesseract.image_to_string(result, lang=\"eng\")\n",
    "        print(text.strip())\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b5194a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "偵測和辨識出車牌文字!\n",
      "ABC-8888\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import pytesseract\n",
    "\n",
    "pytesseract.pytesseract.tesseract_cmd = \"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "img = cv2.imread(\"images/car1.jpg\")\n",
    "model = cv2.dnn.readNet(\"models/frozen_east_text_detection.pb\")\n",
    "outputLayers = []\n",
    "outputLayers.append(\"feature_fusion/Conv_7/Sigmoid\")\n",
    "outputLayers.append(\"feature_fusion/concat_3\")\n",
    "height, width, colorch = img.shape\n",
    "new_height = (height//32+1)*32\n",
    "new_width = (width//32+1)*32\n",
    "h_ratio = height/new_height\n",
    "w_ratio = width/new_width\n",
    "blob = cv2.dnn.blobFromImage(img, 1, (new_width, new_height),\n",
    "                             (123.68, 116.78, 103.94), True)\n",
    "model.setInput(blob)\n",
    "(scores, geometry) = model.forward(outputLayers)\n",
    "rectangles = []\n",
    "confidence_score = []\n",
    "rows = geometry.shape[2]\n",
    "cols = geometry.shape[3]\n",
    "for y in range(0, rows):\n",
    "    for x in range(0, cols):\n",
    "        if scores[0][0][y][x] < 0.5:\n",
    "            continue\n",
    "        offset_x = x*4\n",
    "        offset_y = y*4\n",
    "        bottom_x = int(offset_x + geometry[0][1][y][x])\n",
    "        bottom_y = int(offset_y + geometry[0][2][y][x])\n",
    "        top_x = int(offset_x - geometry[0][3][y][x])\n",
    "        top_y = int(offset_y - geometry[0][0][y][x])\n",
    "        rectangles.append((top_x, top_y, bottom_x, bottom_y))\n",
    "        confidence_score.append(float(scores[0][0][y][x]))\n",
    "\n",
    "final_boxes = non_max_suppression(np.array(rectangles),\n",
    "                                  probs=confidence_score,\n",
    "                                  overlapThresh=0.5)\n",
    "for (x1, y1, x2, y2) in final_boxes:\n",
    "    w = abs(x2-x1)\n",
    "    h = abs(y2-y1)\n",
    "    area = w * h\n",
    "    if area > 4000:\n",
    "        x1 = int(x1*w_ratio)\n",
    "        y1 = int(y1*h_ratio)\n",
    "        x2 = int(x2*w_ratio)\n",
    "        y2 = int(y2*h_ratio)\n",
    "        print(\"偵測和辨識出車牌文字!\")\n",
    "        result = img[y1-5:y1+h+5, x1-1:x1+w+1]\n",
    "        cv2.imshow(\"Plate\", result)\n",
    "        text = pytesseract.image_to_string(result, lang=\"eng\")\n",
    "        print(text.strip())\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6798d8fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\q5j6j\\miniconda3\\envs\\yzu_CV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[np.int32(7), np.int32(47)], [np.int32(193), np.int32(47)], [np.int32(193), np.int32(89)], [np.int32(7), np.int32(89)]], 'K4 P 1 K', np.float64(0.39847019310503506))]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[([[np.int32(5), np.int32(7)], [np.int32(239), np.int32(7)], [np.int32(239), np.int32(51)], [np.int32(5), np.int32(51)]], '清明时节雨纷纷', np.float64(0.9471719233904865)), ([[np.int32(259), np.int32(7)], [np.int32(507), np.int32(7)], [np.int32(507), np.int32(51)], [np.int32(259), np.int32(51)]], '路上行人欲断魂。', np.float64(0.9462622045096404))]\n",
      "[([[np.int32(33), np.int32(35)], [np.int32(449), np.int32(35)], [np.int32(449), np.int32(71)], [np.int32(33), np.int32(71)]], '更改圖片尺寸和製作縮圖', np.float64(0.5309929695577912))]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "回傳結果:\n",
    "1. bounding box:文字區域的邊界框四個點的座標\n",
    "2. text:辨識出來的文字內容\n",
    "3. confidence:信心指數\n",
    "'''\n",
    "\n",
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "reader = easyocr.Reader([\"en\"])\n",
    "result = reader.readtext(\"images/number.jpg\")\n",
    "print(result)\n",
    "\n",
    "reader = easyocr.Reader([\"ch_sim\", \"en\"])\n",
    "img = cv2.imread(\"images/simple.jpg\")\n",
    "result = reader.readtext(img)\n",
    "print(result)\n",
    "\n",
    "reader = easyocr.Reader([\"ch_tra\", \"en\"])\n",
    "with open(\"images/traditional.jpg\", \"rb\") as f:\n",
    "    img = f.read()\n",
    "result = reader.readtext(img)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce1b4264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int32(32), np.int32(159), np.int32(8), np.int32(47)]\n",
      "[np.int32(6), np.int32(191), np.int32(43), np.int32(81)]\n",
      "[np.int32(30), np.int32(178), np.int32(86), np.int32(118)]\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"images/sample.jpg\")\n",
    "reader = easyocr.Reader([\"ch_tra\", \"en\"])\n",
    "horizontal_list, free_list = reader.detect(img)\n",
    "for box in horizontal_list[0]:\n",
    "    print(box)\n",
    "    cv2.rectangle(img, (box[0], box[2]), (box[1], box[3]),\n",
    "                  (0, 0, 255), 3)\n",
    "cv2.imshow(\"Detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4128ee8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\q5j6j\\miniconda3\\envs\\yzu_CV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"images/sample.jpg\")\n",
    "reader = easyocr.Reader([\"ch_tra\", \"en\"])\n",
    "results = reader.readtext(\"images/sample.jpg\")\n",
    "for result in results:\n",
    "    box = result[0]\n",
    "    cv2.rectangle(img, box[0], box[2], (0, 0, 255), 3)\n",
    "cv2.imshow(\"Detection\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f77568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\q5j6j\\miniconda3\\envs\\yzu_CV\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[32, 8], [159, 8], [159, 47], [32, 47]]\n",
      "OpenCV\n",
      "0.9790065595931878\n",
      "[[6, 43], [191, 43], [191, 81], [6, 81]]\n",
      "Python程式設計\n",
      "0.8910885101124186\n",
      "[[30, 86], [178, 86], [178, 118], [30, 118]]\n",
      "DAT-4567\n",
      "0.6394383716097745\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import cv2\n",
    "\n",
    "boxes = [[32, 159, 8, 47],  # horizontal_list[0]\n",
    "         [6, 191, 43, 81],\n",
    "         [30, 178, 86, 118]]\n",
    "\n",
    "img = cv2.imread(\"images/sample.jpg\")\n",
    "reader = easyocr.Reader([\"ch_tra\", \"en\"])\n",
    "results = reader.recognize(img, horizontal_list=boxes,\n",
    "                           free_list=[])\n",
    "for result in results:\n",
    "    print(result[0])\n",
    "    print(result[1])\n",
    "    print(result[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3beb56b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[266 427]\n",
      " [403 413]\n",
      " [405 459]\n",
      " [268 474]]\n",
      "BBT-6566\n"
     ]
    }
   ],
   "source": [
    "import easyocr\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread(\"images/car.jpg\")\n",
    "reader = easyocr.Reader([\"en\"])\n",
    "results = reader.readtext(img)\n",
    "y = 0\n",
    "for box in results:\n",
    "    points = box[0]\n",
    "    points = np.array(points, np.int32)\n",
    "    print(points)\n",
    "    print(box[1])\n",
    "    cv2.polylines(img, pts=[points], isClosed=True,\n",
    "                  color=(0, 0, 255), thickness=3)\n",
    "    y = y + 30\n",
    "    cv2.putText(img, box[1], (10, y),\n",
    "                cv2.FONT_HERSHEY_PLAIN, 2, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"License Plate Recognition\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78142cfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.version.cuda)   # PyTorch 編譯時使用的 CUDA 版本\n",
    "\n",
    "# 檢查 CUDA 是否可用\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "# 顯示偵測到的 GPU 型號\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yzu_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
