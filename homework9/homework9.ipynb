{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5fae6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "src = cv2.imread(\"test.jpg\")\n",
    "src = cv2.resize(src, None, fx=0.5, fy=0.5)\n",
    "temp = cv2.imread('earphone.jpg')\n",
    "temp = cv2.resize(temp, None, fx=0.2, fy=0.2)\n",
    "\n",
    "# mask = np.zeros(src.shape[:2], np.uint8)        # 建立遮罩, 大小和src相同\n",
    "# # mask[10:220, 10:220] = 3                        # 定義可能前景區域\n",
    "# # mask[15:160, 15:160] = 1                        # 定義確定前景區域\n",
    "# bgdModel = np.zeros((1, 65), np.float64)        # 建立內部用暫時計算陣列\n",
    "# fgdModel = np.zeros((1, 65), np.float64)        # 建立內部用暫時計算陣列\n",
    "# rect = (15, 20, 180, 200)                       # 建立ROI區域\n",
    "# src_rect = src.copy()\n",
    "# # cv2.rectangle(src_rect, rect[0:2], rect[2:4], (0, 0, 255), 2)\n",
    "# # cv2.imshow('Rectangle', src_rect)\n",
    "\n",
    "# # 呼叫grabCut()進行分割, 迭代 3 次,回傳mask1\n",
    "# # 其實mask1 = mask, 因為mask也會同步更新\n",
    "# mask1, bgd, fgd = cv2.grabCut(src, mask, rect, bgdModel, fgdModel, 3,\n",
    "#                               cv2.GC_INIT_WITH_RECT)\n",
    "\n",
    "# # 將 0, 2設為0 --- 1, 3設為1\n",
    "# mask2 = np.where((mask1 == 0) | (mask1 == 2), 0, 1).astype('uint8')\n",
    "\n",
    "# dst = src * mask2[:, :, np.newaxis]                 # 計算輸出影像\n",
    "# cv2.imshow('dst', dst)\n",
    "h, w = temp.shape[:2]\n",
    "result = cv2.matchTemplate(src, temp, cv2.TM_CCOEFF_NORMED)\n",
    "for row in range(len(result)):                                      # 找尋row\n",
    "    for col in range(len(result[row])):                             # 找尋column\n",
    "        if result[row][col] > 0.8:                                 # 值大於0.95就算找到了\n",
    "            dst = cv2.rectangle(\n",
    "                src, (col, row), (col+w, row+h), (0, 255, 0), 3)\n",
    "          \n",
    "cv2.imshow(\"Dst\", dst)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135a7c70",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.12.0) D:\\bld\\libopencv_1756075558946\\work\\modules\\core\\src\\dxt.cpp:3517: error: (-215:Assertion failed) type == CV_32FC1 || type == CV_32FC2 || type == CV_64FC1 || type == CV_64FC2 in function 'cv::dft'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31merror\u001b[39m                                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 31\u001b[39m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tracker_list:\n\u001b[32m     30\u001b[39m         area = cv2.selectROI(\u001b[33m'\u001b[39m\u001b[33moxxostudio\u001b[39m\u001b[33m'\u001b[39m, frame, showCrosshair=\u001b[38;5;28;01mFalse\u001b[39;00m, fromCenter=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m         \u001b[43mi\u001b[49m\u001b[43m.\u001b[49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea\u001b[49m\u001b[43m)\u001b[49m    \u001b[38;5;66;03m# 初始化追蹤器\u001b[39;00m\n\u001b[32m     32\u001b[39m     tracking = \u001b[38;5;28;01mTrue\u001b[39;00m            \u001b[38;5;66;03m# 設定可以開始追蹤\u001b[39;00m\n\u001b[32m     33\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tracking:\n",
      "\u001b[31merror\u001b[39m: OpenCV(4.12.0) D:\\bld\\libopencv_1756075558946\\work\\modules\\core\\src\\dxt.cpp:3517: error: (-215:Assertion failed) type == CV_32FC1 || type == CV_32FC2 || type == CV_64FC1 || type == CV_64FC2 in function 'cv::dft'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "tracker_list = []\n",
    "for i in range(3):\n",
    "    tracker = cv2.TrackerCSRT_create()        # 創建三組追蹤器\n",
    "    tracker_list.append(tracker)\n",
    "colors = [(0,0,255),(0,255,255),(255,255,0)]  # 設定三個外框顏色\n",
    "tracking = False                              # 設定 False 表示尚未開始追蹤\n",
    "\n",
    "cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)            # 讀取某個影片\n",
    "a = 0                                         # 刪減影片影格使用\n",
    "if not cap.isOpened():\n",
    "    print(\"Cannot open camera\")\n",
    "    exit()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Cannot receive frame\")\n",
    "        break\n",
    "    frame = cv2.resize(frame,(400,230))       # 縮小尺寸，加快速度\n",
    "    keyName = cv2.waitKey(1)\n",
    "    # 為了避免影片影格太多，所以採用 10 格取一格，加快處理速度\n",
    "    if a%10 == 0:\n",
    "        if keyName == ord('q'):\n",
    "            break\n",
    "        if tracking == False:\n",
    "            # 如果尚未開始追蹤，就開始標記追蹤物件的外框\n",
    "            for i in tracker_list:\n",
    "                area = cv2.selectROI('oxxostudio', frame, showCrosshair=False, fromCenter=False)\n",
    "                i.init(frame, area)    # 初始化追蹤器\n",
    "            tracking = True            # 設定可以開始追蹤\n",
    "        if tracking:\n",
    "            for i in range(len(tracker_list)):\n",
    "                success, point = tracker_list[i].update(frame)   # 追蹤成功後，不斷回傳左上和右下的座標\n",
    "                if success:\n",
    "                    p1 = [int(point[0]), int(point[1])]\n",
    "                    p2 = [int(point[0] + point[2]), int(point[1] + point[3])]\n",
    "                    cv2.rectangle(frame, p1, p2, colors[i], 3)   # 根據座標，繪製四邊形，框住要追蹤的物件\n",
    "\n",
    "        cv2.imshow('oxxostudio', frame)\n",
    "    a = a + 1\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760e4f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# 在 Windows 系統上，嘗試使用 DSHOW\n",
    "# 參數 1 是攝影機索引，第二個參數是 API 偏好\n",
    "api_preference = cv2.CAP_DSHOW\n",
    "capture = cv2.VideoCapture(1, api_preference)\n",
    "'''\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def myMatch(image, tmp, thr=0.95, nms_iou=0.3):\n",
    "    h, w = tmp.shape[:2]\n",
    "    result = cv2.matchTemplate(image, tmp, cv2.TM_CCOEFF_NORMED)\n",
    "    # 取出所有高於門檻的點\n",
    "    boxes, scores = [], []\n",
    "    for x in range(result.shape[1]):\n",
    "        for y in range(result.shape[0]):\n",
    "            boxes.append([int(x), int(y), int(w), int(h)]) # x, y, width, height\n",
    "            scores.append(float(result[y, x]))\n",
    "    # 沒找到就回傳空\n",
    "    if not boxes:\n",
    "        return []\n",
    "    # NMS：只保留不重疊（或低重疊）的高分框\n",
    "    indices = cv2.dnn.NMSBoxes(\n",
    "        boxes, scores, score_threshold=thr, nms_threshold=nms_iou)\n",
    "    final = []\n",
    "    if len(indices) > 0:\n",
    "        for i in indices.flatten():\n",
    "            x, y, bw, bh = boxes[i]\n",
    "            final.append(((x, y), (x + bw, y + bh)))\n",
    "    return final\n",
    "\n",
    "src = cv2.imread(\"test.jpg\", cv2.IMREAD_COLOR)\n",
    "src = cv2.resize(src, None, fx=0.3, fy=0.3)\n",
    "temps = [cv2.imread(\"mouse.jpg\", cv2.IMREAD_COLOR),\n",
    "         cv2.imread(\"earphone.jpg\", cv2.IMREAD_COLOR)]\n",
    "cv2.imshow(\"src\", src)\n",
    "match = []\n",
    "for i in range(len(temps)):\n",
    "    temps[i] = cv2.resize(temps[i], None, fx=0.2, fy=0.2)\n",
    "    cv2.imshow(f\"temps{i}\", temps[i])\n",
    "for i in range(len(temps)):\n",
    "    h, w = temps[i].shape[:2]\n",
    "    result = cv2.matchTemplate(src, temps[i], cv2.TM_CCOEFF_N)\n",
    "    cv2.imshow(f\"temps{i}\", result)\n",
    "    # match += myMatch(src, t, thr=0.7)\n",
    "# for pt1, pt2 in match:\n",
    "#     cv2.rectangle(src, pt1, pt2, (0, 255, 0), 2)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yzu_CV",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
